{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importa la biblioteca pandas.\n",
    "\n",
    "# Cargar datos de prueba desde un archivo zip.\n",
    "test_data = pd.read_csv(\n",
    "    \"../files/input/test_data.csv.zip\", # Especifica la ruta relativa al archivo .zip que contiene los datos de prueba.\n",
    "    index_col=False, # Indica que no se debe usar ninguna columna como índice del DataFrame.    \n",
    "    compression=\"zip\", # Especifica que el archivo está comprimido como un .zip.\n",
    ")\n",
    "\n",
    "# Cargar datos de entrenamiento desde un archivo zip.\n",
    "train_data = pd.read_csv(\n",
    "    \"../files/input/train_data.csv.zip\", # Especifica la ruta relativa al archivo .zip que contiene los datos de entrenamiento.\n",
    "    index_col=False, # Indica que no se debe usar ninguna columna como índice del DataFrame.\n",
    "    compression=\"zip\", # Especifica que el archivo está comprimido como un .zip.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# limpieza de datos\n",
    "#\n",
    "\n",
    "# Cree la columna 'Age' a partir de la columna 'Year' (Asuma que el año actual es 2021).\n",
    "test_data['Age'] = 2021 - test_data['Year']\n",
    "train_data['Age'] = 2021 - train_data['Year']\n",
    "\n",
    "\n",
    "# Elimine las columnas 'Year' y 'Car_Name'.\n",
    "test_data = test_data.drop(columns=['Year','Car_Name'])\n",
    "train_data = train_data.drop(columns=['Year','Car_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# separacion de los datos\n",
    "#\n",
    "\n",
    "# Elimina la columna 'Present_Price' del DataFrame train_data para crear el conjunto de características de entrenamiento.\n",
    "x_train = train_data.drop(columns=\"Present_Price\")\n",
    "\n",
    "# Extrae la columna 'Present_Price' de train_data y la usa como el conjunto de etiquetas de entrenamiento.\n",
    "y_train = train_data[\"Present_Price\"]\n",
    "\n",
    "# Elimina la columna 'Present_Price' del DataFrame test_data para crear el conjunto de características de prueba\n",
    "x_test = test_data.drop(columns=\"Present_Price\")\n",
    "\n",
    "# Extrae la columna 'Present_Price' de test_data y la usa como el conjunto de etiquetas de prueba.\n",
    "y_test = test_data[\"Present_Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# eleccion modelo y transformaciones\n",
    "#\n",
    "\n",
    "from sklearn.compose import ColumnTransformer # Aplica transformaciones específicas a subconjuntos de columnas (categóricas y numéricas).\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline # Permite encadenar varios pasos como preprocesamiento, selección de características y modelado.\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler # Herramientas para escalar y codificar datos.\n",
    "from sklearn.feature_selection import f_regression,SelectKBest # Selecciona las mejores características basadas en una métrica estadística.\n",
    "\n",
    "# Definición de las columnas categóricas y numéricas.\n",
    "categorical_features=['Fuel_Type','Selling_type','Transmission'] # Lista de columnas categóricas.\n",
    "numerical_features= x_train.columns.difference(categorical_features + [\"default\"]).tolist()  # Lista de columnas numéricas.\n",
    "\n",
    "# Configuración del preprocesador.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features), # Codifica variables categóricas.\n",
    "        ('scaler',MinMaxScaler(),numerical_features), # Escala las variables numéricas para tener media 0 y desviación estándar 1.\n",
    "    ],\n",
    "    remainder='passthrough'  # Pasa sin cambios las columnas que no están incluidas en 'transformers'.\n",
    ")\n",
    "\n",
    "# Creación del pipeline.\n",
    "pipeline=Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\",preprocessor), # Aplica las transformaciones del preprocesador\n",
    "        ('feature_selection',SelectKBest(f_regression)), # Selecciona las características más relevantes.\n",
    "        ('classifier', LinearRegression()) # Aplica el modelo de regresión lineal como clasificador.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'classifier__fit_intercept': True, 'classifier__positive': True, 'feature_selection__k': 11}\n",
      "Mejor precisión balanceada: -1.765768769272933\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# hiperparametros y ajuste\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV  # Herramienta para buscar automáticamente la mejor combinación de hiperparámetros.\n",
    "\n",
    "# Definición de la rejilla de parámetros para la búsqueda.\n",
    "param_grid = {\n",
    "    'feature_selection__k': range(1, 15),  # Número de características a seleccionar en SelectKBest (de 1 a 14).\n",
    "    'classifier__fit_intercept': [True, False],  # Si se ajusta el intercepto (constante) en el modelo de clasificación.\n",
    "    'classifier__positive': [True, False]  # Si se restringen los coeficientes a ser positivos (solo válido para ciertos clasificadores).\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV.\n",
    "model = GridSearchCV(\n",
    "    pipeline,  # Pipeline que incluye preprocesamiento, selección de características y modelo de clasificación.\n",
    "    param_grid,  # Rejilla de hiperparámetros definida anteriormente.\n",
    "    cv=10,  # Número de particiones para la validación cruzada (10 particiones en este caso).\n",
    "    scoring=\"neg_mean_absolute_error\",  # Métrica de evaluación: error absoluto medio negativo (se usará su valor positivo como resultado).\n",
    "    n_jobs=-1,  # Usa todos los núcleos disponibles para procesar en paralelo, acelerando la búsqueda.\n",
    ")\n",
    "# Ajusta el modelo en el conjunto de entrenamiento.\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor score.\n",
    "print(\"Mejores parámetros:\", model.best_params_)\n",
    "print(\"Mejor precisión balanceada:\", model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejores parámetros: {'classifier__fit_intercept': True, 'classifier__positive': True, 'feature_selection__k': 11}\n",
    "\n",
    "Mejor precisión balanceada: -1.765768769272933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../files/models/model.pkl.gz'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# guardar modelo\n",
    "#\n",
    "\n",
    "import gzip  # Para comprimir y descomprimir archivos.\n",
    "import pickle  # Para serializar y deserializar objetos de Python, como modelos de machine learning.\n",
    "import os  # Para manejo de directorios.\n",
    "\n",
    "models_dir = '../files/models'  # Define la ruta donde se guardarán los modelos.\n",
    "os.makedirs(models_dir, exist_ok=True)  # Crea el directorio si no existe.\n",
    "\n",
    "model_path = \"../files/models/model.pkl.gz\"  # Define la ruta completa para el archivo del modelo.\n",
    "\n",
    "with gzip.open(model_path, \"wb\") as f:  # Abre el archivo en modo escritura binaria ('wb') y comprime el contenido.\n",
    "    pickle.dump(model, f)  # Serializa el objeto del modelo y lo guarda en el archivo comprimido.\n",
    "\n",
    "model_path  # Devuelve la ruta donde se guardó el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# funcion ejecutura y salva las metricas\n",
    "#\n",
    "\n",
    "import json  # Biblioteca para manejar datos en formato JSON.\n",
    "import os  # Biblioteca para operaciones de manejo de directorios y archivos.\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error  # Métricas de evaluación para regresión.\n",
    "\n",
    "def calculate_and_save_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Calcula métricas de evaluación para un modelo entrenado en conjuntos de entrenamiento y prueba,\n",
    "    e imprime y guarda estas métricas en un archivo JSON.\n",
    "    \"\"\"\n",
    "    # Hacer predicciones en los conjuntos de entrenamiento y prueba.\n",
    "    y_train_pred = model.predict(X_train)  # Predicciones para el conjunto de entrenamiento.\n",
    "    y_test_pred = model.predict(X_test)  # Predicciones para el conjunto de prueba.\n",
    "\n",
    "    # Calcular métricas para el conjunto de entrenamiento.\n",
    "    metrics_train = {\n",
    "        'type': 'metrics',  # Identifica que es un conjunto de métricas.\n",
    "        'dataset': 'train',  # Indica que estas métricas son del conjunto de entrenamiento.\n",
    "        'r2': float(r2_score(y_train, y_train_pred)),  # Coeficiente de determinación R².\n",
    "        'mse': float(mean_squared_error(y_train, y_train_pred)),  # Error cuadrático medio (MSE).\n",
    "        'mad': float(median_absolute_error(y_train, y_train_pred))  # Error absoluto mediano (MAD).\n",
    "    }\n",
    "\n",
    "    # Imprimir métricas del conjunto de entrenamiento.\n",
    "    print(\"Train Metrics:\", metrics_train)\n",
    "\n",
    "    # Calcular métricas para el conjunto de prueba.\n",
    "    metrics_test = {\n",
    "        'type': 'metrics',  # Identifica que es un conjunto de métricas.\n",
    "        'dataset': 'test',  # Indica que estas métricas son del conjunto de prueba.\n",
    "        'r2': float(r2_score(y_test, y_test_pred)),  # Coeficiente de determinación R².\n",
    "        'mse': float(mean_squared_error(y_test, y_test_pred)),  # Error cuadrático medio (MSE).\n",
    "        'mad': float(median_absolute_error(y_test, y_test_pred))  # Error absoluto mediano (MAD).\n",
    "    }\n",
    "\n",
    "    # Imprimir métricas del conjunto de prueba.\n",
    "    print(\"Test Metrics:\", metrics_test)\n",
    "\n",
    "    # Crear carpeta de salida si no existe.\n",
    "    output_dir = '../files/output'  # Directorio donde se guardarán las métricas.\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Crea el directorio si no existe.\n",
    "\n",
    "    # Guardar las métricas en un archivo JSON.\n",
    "    output_path = os.path.join(output_dir, 'metrics.json')  # Ruta completa del archivo JSON.\n",
    "    with open(output_path, 'w') as f:  # Abrir el archivo en modo escritura ('w') para crear un archivo limpio.\n",
    "        f.write(json.dumps(metrics_train) + '\\n')  # Escribir las métricas de entrenamiento en formato JSON.\n",
    "        f.write(json.dumps(metrics_test) + '\\n')  # Escribir las métricas de prueba en formato JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics: {'type': 'metrics', 'dataset': 'train', 'r2': 0.8916962358587399, 'mse': 5.8746462805982045, 'mad': 1.092912344019548}\n",
      "Test Metrics: {'type': 'metrics', 'dataset': 'test', 'r2': 0.7325716754123306, 'mse': 32.56667275386626, 'mad': 1.5033540603205706}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "calculate_and_save_metrics(model, x_train, x_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
